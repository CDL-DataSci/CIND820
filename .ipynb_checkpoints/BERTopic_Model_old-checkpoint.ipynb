{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "from pdfminer.high_level import extract_text\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import download\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "import os\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pdfplumber\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import HdpModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No preprocessing is needed for BERTopic\n",
    "# Just keep the text in its original form\n",
    "\n",
    "# Create a dictionary from the preprocessed text\n",
    "# BERTopic does not require a dictionary or bag-of-words representation\n",
    "\n",
    "# Create a corpus\n",
    "# BERTopic does not require a corpus with bag-of-words representation\n",
    "# Instead, BERTopic directly works with the text data to generate embeddings\n",
    "\n",
    "# texts variable now contains the raw text from the PDFs, which can be used directly for BERTopic\n",
    "\n",
    "# Directory path containing PDF files\n",
    "pdf_directory = '/Users/cdlacey/TMU_DataScience/CIND820/Dataset_BERTopic'\n",
    "\n",
    "# List all PDF files in the directory\n",
    "pdf_files = [os.path.join(pdf_directory, file) for file in os.listdir(pdf_directory) if file.endswith('.pdf')]\n",
    "\n",
    "texts = []\n",
    "\n",
    "# Loop through each PDF file and extract text\n",
    "for pdf_file in pdf_files:\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "        texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c370a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Train the BERTopic model\n",
    "bertopic_model = BERTopic()\n",
    "topics, _ = bertopic_model.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ebe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Step 1: Convert Texts to Sentence Embeddings\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate sentence embeddings for each document\n",
    "sentence_embeddings = model.encode(preprocessed_texts)\n",
    "\n",
    "# Step 2: Fit BERTopic Model\n",
    "# Initialize BERTopic model\n",
    "bertopic_model = BERTopic()\n",
    "\n",
    "# Fit BERTopic model to the sentence embeddings\n",
    "topics, _ = bertopic_model.fit_transform(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44155071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
